from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup, Comment
import re
import json
import time
import os
from datetime import datetime

# === INPUT ===
# target URLS here
urls = [

]
# target keywords here
keywords = []

header_tags = {"h1", "h2", "h3", "h4"}

# === HELPERS ===
def tag_visible(element):
    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]', 'noscript']:
        return False
    if isinstance(element, Comment):
        return False
    return True

def sanitize_filename(url):
    return url.replace("https://", "").replace("http://", "").replace("/", "_")

def scrape_with_playwright(urls, keywords):
    matches = []


    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            viewport={"width": 1280, "height": 800},
            java_script_enabled=True,
            locale="en-US"
        )
        page = context.new_page()
        page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

        for url in urls:
            print(f"\nüîó Scanning: {url}")
            try:
                matched_keywords_in_headers = set()

                page.goto(url, timeout=60000, wait_until='domcontentloaded')
                page.wait_for_timeout(5000)


                html = page.content()
                soup = BeautifulSoup(html, 'html.parser')
                texts = soup.find_all(string=True)
                visible_texts = filter(tag_visible, texts)

                for text in visible_texts:
                    clean = text.strip()
                    if not clean:
                        continue

                    for kw in keywords:
                        if re.search(rf'\b{re.escape(kw)}\b', clean, re.IGNORECASE):
                            tag_name = text.parent.name.lower()

                            # Skip if same keyword was already captured in a header tag
                            if kw in matched_keywords_in_headers and tag_name not in header_tags:
                                print(f"‚è≠Ô∏è Skipped '{kw}' in <{tag_name}> (already matched in header): {clean}")
                                break

                            print(f"‚úÖ {clean} (matched: {kw}) from <{tag_name}>")
                            match_record = {
                                'url': url,
                                'text': clean,
                                'keyword': kw,
                                'tag': tag_name
                            }
                            matches.append(match_record)

                            if tag_name in header_tags:
                                matched_keywords_in_headers.add(kw)

                            break

            except Exception as e:
                print(f"‚ùå Error with {url}: {e}")
                matches.append({
                    'url': url,
                    'error': str(e)
                })

        browser.close()
    return matches

# === MAIN RUN ===
if __name__ == "__main__":
    results = scrape_with_playwright(urls, keywords)

    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_file = f"keyword_headlines_{timestamp}.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\nüìù Results saved to: {output_file}")

